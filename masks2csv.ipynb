{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "masks2csv.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpGQl0tCAdy_"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imread\n",
        "import sys\n",
        "%matplotlib inline\n",
        "\n",
        "# encoding function\n",
        "# based on the implementation: https://www.kaggle.com/rakhlin/fast-run-length-encoding-python/code\n",
        "def rle_encoding(x):\n",
        "  '''x: numpy array of shape (height, width), 1 - mask, 0 - background\n",
        "  Returns run length as list\n",
        "  '''\n",
        "  dots = np.where(x.T.flatten()==1)[0] # .T sets Fortran order down-then-right\n",
        "  run_lengths = []\n",
        "  prev = -2\n",
        "  for b in dots:\n",
        "    if (b>prev+1): run_lengths.extend((b+1, 0))\n",
        "    run_lengths[-1] += 1\n",
        "    prev = b\n",
        "  return run_lengths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPmk_RYOA5xO",
        "outputId": "e4c30dfa-71f3-45ee-a80c-1919156c184f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Use Google Drive as Data Storage\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZPjahVRAm41",
        "outputId": "6dfcde64-d03a-43e0-b064-e21ee3bb1bef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "import datetime\n",
        "\n",
        "# (* update) the input_path using your folder path\n",
        "input_path = './gdrive/My Drive/Colab Notebooks/datasets/hairSeg/test_mask_preds/'\n",
        "\n",
        "# get a sorted list of all mask filenames in the folder\n",
        "masks = [f for f in os.listdir(input_path) if f.endswith('.jpg')]\n",
        "masks = sorted(masks, key=lambda s:int(s.split('_')[2].split('.')[0]))\n",
        "\n",
        "# encode all masks\n",
        "encodings = []\n",
        "for i, file in tqdm(enumerate(masks), total=len(masks)):\n",
        "  mask = imread(os.path.join(input_path, file))\n",
        "  #img_size =10\n",
        "  #mask = resize(mask, (img_size, img_size), mode='constant', preserve_range=True)\n",
        "  mask = np.array(mask, dtype=np.uint8)\n",
        "  mask = np.round(mask/255)\n",
        "  encodings.append(rle_encoding(mask))\n",
        "\n",
        "# (** update) the path where to save the submission csv file\n",
        "sub = pd.DataFrame()\n",
        "sub['ImageId'] = pd.Series(masks).apply(lambda x: os.path.splitext(x)[0])\n",
        "sub['EncodedPixels'] = pd.Series(encodings).apply(lambda x: ' '.join(str(y) for y in x))\n",
        "sub.to_csv(os.path.join('./gdrive/My Drive/Colab Notebooks/CS4210/', 'test_mask_preds_'+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+'.csv'), index=False)\n",
        "sys.stdout.flush()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 927/927 [04:55<00:00,  3.14it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}